{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe37cd3e-99df-4166-a1d0-1065539b0084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> merge config from configs/dat_tiny.yaml\n",
      "\u001b[32m[2024-03-20 21:57:31 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 108)\u001b[0m: INFO Full config saved to output/dat_plus_plus/tes/config.yaml\n",
      "\u001b[32m[2024-03-20 21:57:31 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 111)\u001b[0m: INFO AMP: true\n",
      "AUG:\n",
      "  AUTO_AUGMENT: rand-m9-mstd0.5-inc1\n",
      "  COLOR_JITTER: 0.4\n",
      "  CUTMIX: 1.0\n",
      "  CUTMIX_MINMAX: null\n",
      "  MIXUP: 0.8\n",
      "  MIXUP_MODE: batch\n",
      "  MIXUP_PROB: 1.0\n",
      "  MIXUP_SWITCH_PROB: 0.5\n",
      "  RECOUNT: 1\n",
      "  REMODE: pixel\n",
      "  REPROB: 0.25\n",
      "BASE:\n",
      "- ''\n",
      "DATA:\n",
      "  BATCH_SIZE: 128\n",
      "  DATASET: imagenet\n",
      "  DATA_PATH: /workspace/cifar\n",
      "  IMG_SIZE: 224\n",
      "  INTERPOLATION: bicubic\n",
      "  NUM_WORKERS: 8\n",
      "  PIN_MEMORY: true\n",
      "EVAL_MODE: false\n",
      "LOCAL_RANK: 0\n",
      "MODEL:\n",
      "  DAT:\n",
      "    attn_drop_rate: 0.0\n",
      "    depths:\n",
      "    - 2\n",
      "    - 4\n",
      "    - 18\n",
      "    - 2\n",
      "    dim_stem: 64\n",
      "    dims:\n",
      "    - 64\n",
      "    - 128\n",
      "    - 256\n",
      "    - 512\n",
      "    drop_path_rate: 0.2\n",
      "    drop_rate: 0.0\n",
      "    dwc_pes:\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    expansion: 4\n",
      "    fixed_pes:\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    groups:\n",
      "    - 1\n",
      "    - 2\n",
      "    - 4\n",
      "    - 8\n",
      "    heads:\n",
      "    - 2\n",
      "    - 4\n",
      "    - 8\n",
      "    - 16\n",
      "    img_size: 224\n",
      "    ksizes:\n",
      "    - 9\n",
      "    - 7\n",
      "    - 5\n",
      "    - 3\n",
      "    nat_ksizes:\n",
      "    - 7\n",
      "    - 7\n",
      "    - 7\n",
      "    - 7\n",
      "    no_offs:\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    - false\n",
      "    num_classes: 1000\n",
      "    offset_range_factor:\n",
      "    - -1\n",
      "    - -1\n",
      "    - -1\n",
      "    - -1\n",
      "    patch_size: 4\n",
      "    stage_spec:\n",
      "    - - N\n",
      "      - D\n",
      "    - - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "    - - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "      - N\n",
      "      - D\n",
      "    - - D\n",
      "      - D\n",
      "    strides:\n",
      "    - 8\n",
      "    - 4\n",
      "    - 2\n",
      "    - 1\n",
      "    use_conv_patches: true\n",
      "    use_dwc_mlps:\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    use_lpus:\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    use_pes:\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    - true\n",
      "    window_sizes:\n",
      "    - 7\n",
      "    - 7\n",
      "    - 7\n",
      "    - 7\n",
      "  DROP_PATH_RATE: 0.1\n",
      "  DROP_RATE: 0.0\n",
      "  LABEL_SMOOTHING: 0.1\n",
      "  NAME: dat_plus_plus\n",
      "  NUM_CLASSES: 1000\n",
      "  PRETRAINED: null\n",
      "  RESUME: dat_pp_tiny_in1k_224.pth\n",
      "  TYPE: dat\n",
      "OUTPUT: output/dat_plus_plus/tes\n",
      "PRINT_FREQ: 100\n",
      "SAVE_FREQ: 1\n",
      "SEED: 0\n",
      "TAG: tes\n",
      "TEST:\n",
      "  CROP: true\n",
      "THROUGHPUT_MODE: false\n",
      "TRAIN:\n",
      "  AUTO_RESUME: true\n",
      "  BASE_LR: 0.000125\n",
      "  CLIP_GRAD: 5.0\n",
      "  EPOCHS: 300\n",
      "  LR_SCHEDULER:\n",
      "    DECAY_EPOCHS: 30\n",
      "    DECAY_RATE: 0.1\n",
      "    NAME: cosine\n",
      "  MIN_LR: 1.25e-06\n",
      "  OPTIMIZER:\n",
      "    BETAS:\n",
      "    - 0.9\n",
      "    - 0.999\n",
      "    EPS: 1.0e-08\n",
      "    MOMENTUM: 0.9\n",
      "    NAME: adamw\n",
      "  START_EPOCH: 0\n",
      "  USE_CHECKPOINT: false\n",
      "  WARMUP_EPOCHS: 20\n",
      "  WARMUP_LR: 1.25e-07\n",
      "  WEIGHT_DECAY: 0.05\n",
      "\n",
      "\u001b[32m[2024-03-20 21:57:31 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 115)\u001b[0m: INFO Creating model:dat/dat_plus_plus\n",
      "\u001b[32m[2024-03-20 21:57:32 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 119)\u001b[0m: INFO DAT(\n",
      "  (patch_proj): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LayerNormProxy(\n",
      "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): LayerNormProxy(\n",
      "      (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (stages): ModuleList(\n",
      "    (0): TransformerStage(\n",
      "      (proj): Identity()\n",
      "      (ln_cnvnxt): ModuleDict()\n",
      "      (layer_norms): ModuleList(\n",
      "        (0-3): 4 x LayerNormProxy(\n",
      "          (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (mlps): ModuleList(\n",
      "        (0-1): 2 x TransformerMLPWithConv(\n",
      "          (linear1): Sequential(\n",
      "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop1): Dropout(p=0.0, inplace=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (linear2): Sequential(\n",
      "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop2): Dropout(p=0.0, inplace=True)\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "        )\n",
      "      )\n",
      "      (attns): ModuleList(\n",
      "        (0): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=64, out_features=192, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(9, 9), stride=(8, 8), padding=(4, 4), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): ModuleList(\n",
      "        (0): Identity()\n",
      "        (1): DropPath(drop_prob=0.008)\n",
      "      )\n",
      "      (layer_scales): ModuleList(\n",
      "        (0-3): 4 x Identity()\n",
      "      )\n",
      "      (local_perception_units): ModuleList(\n",
      "        (0-1): 2 x Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerStage(\n",
      "      (proj): Identity()\n",
      "      (ln_cnvnxt): ModuleDict()\n",
      "      (layer_norms): ModuleList(\n",
      "        (0-7): 8 x LayerNormProxy(\n",
      "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (mlps): ModuleList(\n",
      "        (0-3): 4 x TransformerMLPWithConv(\n",
      "          (linear1): Sequential(\n",
      "            (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop1): Dropout(p=0.0, inplace=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (linear2): Sequential(\n",
      "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop2): Dropout(p=0.0, inplace=True)\n",
      "          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "        )\n",
      "      )\n",
      "      (attns): ModuleList(\n",
      "        (0): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (2): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (3): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): ModuleList(\n",
      "        (0): DropPath(drop_prob=0.016)\n",
      "        (1): DropPath(drop_prob=0.024)\n",
      "        (2): DropPath(drop_prob=0.032)\n",
      "        (3): DropPath(drop_prob=0.040)\n",
      "      )\n",
      "      (layer_scales): ModuleList(\n",
      "        (0-7): 8 x Identity()\n",
      "      )\n",
      "      (local_perception_units): ModuleList(\n",
      "        (0-3): 4 x Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerStage(\n",
      "      (proj): Identity()\n",
      "      (ln_cnvnxt): ModuleDict()\n",
      "      (layer_norms): ModuleList(\n",
      "        (0-35): 36 x LayerNormProxy(\n",
      "          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (mlps): ModuleList(\n",
      "        (0-17): 18 x TransformerMLPWithConv(\n",
      "          (linear1): Sequential(\n",
      "            (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop1): Dropout(p=0.0, inplace=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (linear2): Sequential(\n",
      "            (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop2): Dropout(p=0.0, inplace=True)\n",
      "          (dwc): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
      "        )\n",
      "      )\n",
      "      (attns): ModuleList(\n",
      "        (0): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (1): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (2): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (3): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (4): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (5): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (6): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (7): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (8): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (9): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (10): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (11): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (12): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (13): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (14): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (15): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "        (16): NeighborhoodAttention2D(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (17): DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): ModuleList(\n",
      "        (0): DropPath(drop_prob=0.048)\n",
      "        (1): DropPath(drop_prob=0.056)\n",
      "        (2): DropPath(drop_prob=0.064)\n",
      "        (3): DropPath(drop_prob=0.072)\n",
      "        (4): DropPath(drop_prob=0.080)\n",
      "        (5): DropPath(drop_prob=0.088)\n",
      "        (6): DropPath(drop_prob=0.096)\n",
      "        (7): DropPath(drop_prob=0.104)\n",
      "        (8): DropPath(drop_prob=0.112)\n",
      "        (9): DropPath(drop_prob=0.120)\n",
      "        (10): DropPath(drop_prob=0.128)\n",
      "        (11): DropPath(drop_prob=0.136)\n",
      "        (12): DropPath(drop_prob=0.144)\n",
      "        (13): DropPath(drop_prob=0.152)\n",
      "        (14): DropPath(drop_prob=0.160)\n",
      "        (15): DropPath(drop_prob=0.168)\n",
      "        (16): DropPath(drop_prob=0.176)\n",
      "        (17): DropPath(drop_prob=0.184)\n",
      "      )\n",
      "      (layer_scales): ModuleList(\n",
      "        (0-35): 36 x Identity()\n",
      "      )\n",
      "      (local_perception_units): ModuleList(\n",
      "        (0-17): 18 x Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerStage(\n",
      "      (proj): Identity()\n",
      "      (ln_cnvnxt): ModuleDict()\n",
      "      (layer_norms): ModuleList(\n",
      "        (0-3): 4 x LayerNormProxy(\n",
      "          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (mlps): ModuleList(\n",
      "        (0-1): 2 x TransformerMLPWithConv(\n",
      "          (linear1): Sequential(\n",
      "            (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop1): Dropout(p=0.0, inplace=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (linear2): Sequential(\n",
      "            (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (drop2): Dropout(p=0.0, inplace=True)\n",
      "          (dwc): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)\n",
      "        )\n",
      "      )\n",
      "      (attns): ModuleList(\n",
      "        (0-1): 2 x DAttentionBaseline(\n",
      "          (conv_offset): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (1): LayerNormProxy(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            )\n",
      "            (2): GELU(approximate='none')\n",
      "            (3): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          )\n",
      "          (proj_q): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_k): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_v): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_out): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (proj_drop): Dropout(p=0.0, inplace=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (drop_path): ModuleList(\n",
      "        (0): DropPath(drop_prob=0.192)\n",
      "        (1): DropPath(drop_prob=0.200)\n",
      "      )\n",
      "      (layer_scales): ModuleList(\n",
      "        (0-3): 4 x Identity()\n",
      "      )\n",
      "      (local_perception_units): ModuleList(\n",
      "        (0-1): 2 x Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down_projs): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LayerNormProxy(\n",
      "        (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LayerNormProxy(\n",
      "        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): LayerNormProxy(\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (cls_norm): LayerNormProxy(\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (cls_head): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "\u001b[32m[2024-03-20 21:57:32 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 18)\u001b[0m: INFO ==============> Resuming form dat_pp_tiny_in1k_224.pth....................\n",
      "\u001b[32m[2024-03-20 21:57:32 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 25)\u001b[0m: INFO <All keys matched successfully>\n",
      "\u001b[32m[2024-03-20 21:57:48 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 0.000 Acc@5 0.070\n",
      "\u001b[32m[2024-03-20 21:57:48 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 160)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 0.0%\n",
      "\u001b[32m[2024-03-20 21:57:48 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 167)\u001b[0m: INFO Start training\n",
      "\u001b[32m[2024-03-20 21:58:37 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [1/300][100/390]\teta 0:02:21 lr 0.000002\ttime 0.4321 (0.4875)\tloss 7.2006 (7.9427)\tgrad_norm 18.0423 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 21:59:20 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [1/300][200/390]\teta 0:01:27 lr 0.000003\ttime 0.4321 (0.4587)\tloss 4.7240 (6.9324)\tgrad_norm 13.2347 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:00:03 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [1/300][300/390]\teta 0:00:40 lr 0.000005\ttime 0.4288 (0.4492)\tloss 3.3620 (5.9420)\tgrad_norm 8.5039 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:00:42 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 1 training takes 0:02:53\n",
      "\u001b[32m[2024-03-20 22:00:42 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_1.pth saving......\n",
      "\u001b[32m[2024-03-20 22:00:42 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_1.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:00:55 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 30.180 Acc@5 84.700\n",
      "\u001b[32m[2024-03-20 22:00:55 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 30.2%\n",
      "\u001b[32m[2024-03-20 22:00:55 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 30.18%\n",
      "\u001b[32m[2024-03-20 22:01:39 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [2/300][100/390]\teta 0:02:07 lr 0.000008\ttime 0.4336 (0.4397)\tloss 2.8631 (3.0118)\tgrad_norm 7.4186 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:02:22 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [2/300][200/390]\teta 0:01:23 lr 0.000010\ttime 0.4355 (0.4348)\tloss 3.0075 (2.9668)\tgrad_norm 5.2723 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:03:05 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [2/300][300/390]\teta 0:00:39 lr 0.000011\ttime 0.4314 (0.4332)\tloss 2.6222 (2.9200)\tgrad_norm 6.2701 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:03:43 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 2 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:03:43 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_2.pth saving......\n",
      "\u001b[32m[2024-03-20 22:03:44 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_2.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:03:56 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 59.860 Acc@5 95.550\n",
      "\u001b[32m[2024-03-20 22:03:56 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 59.9%\n",
      "\u001b[32m[2024-03-20 22:03:56 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 59.86%\n",
      "\u001b[32m[2024-03-20 22:04:40 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [3/300][100/390]\teta 0:02:08 lr 0.000014\ttime 0.4292 (0.4405)\tloss 2.3893 (2.6716)\tgrad_norm 5.6347 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:05:23 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [3/300][200/390]\teta 0:01:23 lr 0.000016\ttime 0.4291 (0.4349)\tloss 2.7320 (2.6633)\tgrad_norm 5.7722 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:06:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [3/300][300/390]\teta 0:00:39 lr 0.000017\ttime 0.4305 (0.4329)\tloss 2.7215 (2.6450)\tgrad_norm 11.1534 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:06:44 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 3 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:06:44 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_3.pth saving......\n",
      "\u001b[32m[2024-03-20 22:06:45 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_3.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:06:57 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 74.430 Acc@5 98.100\n",
      "\u001b[32m[2024-03-20 22:06:57 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 74.4%\n",
      "\u001b[32m[2024-03-20 22:06:57 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 74.43%\n",
      "\u001b[32m[2024-03-20 22:07:41 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [4/300][100/390]\teta 0:02:07 lr 0.000020\ttime 0.4290 (0.4397)\tloss 2.3847 (2.5420)\tgrad_norm 4.1099 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:08:24 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [4/300][200/390]\teta 0:01:23 lr 0.000022\ttime 0.4298 (0.4348)\tloss 2.4753 (2.5267)\tgrad_norm 4.5487 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:09:07 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [4/300][300/390]\teta 0:00:39 lr 0.000024\ttime 0.4306 (0.4332)\tloss 2.5452 (2.5170)\tgrad_norm 12.9969 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:09:46 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 4 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:09:46 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_4.pth saving......\n",
      "\u001b[32m[2024-03-20 22:09:46 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_4.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:09:58 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 81.990 Acc@5 99.200\n",
      "\u001b[32m[2024-03-20 22:09:58 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 82.0%\n",
      "\u001b[32m[2024-03-20 22:09:58 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 81.99%\n",
      "\u001b[32m[2024-03-20 22:10:42 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [5/300][100/390]\teta 0:02:07 lr 0.000027\ttime 0.4296 (0.4389)\tloss 2.6717 (2.3857)\tgrad_norm 4.6508 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:11:25 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [5/300][200/390]\teta 0:01:22 lr 0.000028\ttime 0.4290 (0.4342)\tloss 2.6969 (2.3775)\tgrad_norm 6.4969 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:12:08 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [5/300][300/390]\teta 0:00:39 lr 0.000030\ttime 0.4278 (0.4326)\tloss 2.4018 (2.3797)\tgrad_norm 11.3613 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:12:47 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 5 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:12:47 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_5.pth saving......\n",
      "\u001b[32m[2024-03-20 22:12:47 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_5.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:12:59 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 87.440 Acc@5 99.550\n",
      "\u001b[32m[2024-03-20 22:12:59 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 87.4%\n",
      "\u001b[32m[2024-03-20 22:12:59 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 87.44%\n",
      "\u001b[32m[2024-03-20 22:13:44 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [6/300][100/390]\teta 0:02:08 lr 0.000033\ttime 0.4307 (0.4402)\tloss 2.2906 (2.3286)\tgrad_norm 6.7473 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:14:26 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [6/300][200/390]\teta 0:01:23 lr 0.000035\ttime 0.4320 (0.4350)\tloss 2.0228 (2.3277)\tgrad_norm 11.4791 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:15:09 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [6/300][300/390]\teta 0:00:39 lr 0.000036\ttime 0.4280 (0.4333)\tloss 2.0720 (2.3127)\tgrad_norm 6.5334 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:15:48 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 6 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:15:48 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_6.pth saving......\n",
      "\u001b[32m[2024-03-20 22:15:49 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_6.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:16:01 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 89.850 Acc@5 99.750\n",
      "\u001b[32m[2024-03-20 22:16:01 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 89.8%\n",
      "\u001b[32m[2024-03-20 22:16:01 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 89.85%\n",
      "\u001b[32m[2024-03-20 22:16:45 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [7/300][100/390]\teta 0:02:07 lr 0.000039\ttime 0.4288 (0.4398)\tloss 2.3873 (2.2708)\tgrad_norm 5.4876 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:17:28 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [7/300][200/390]\teta 0:01:23 lr 0.000041\ttime 0.4287 (0.4347)\tloss 2.5365 (2.2773)\tgrad_norm 11.5983 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:18:11 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [7/300][300/390]\teta 0:00:39 lr 0.000042\ttime 0.4273 (0.4330)\tloss 2.5540 (2.2821)\tgrad_norm 9.1412 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:18:49 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 7 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:18:49 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_7.pth saving......\n",
      "\u001b[32m[2024-03-20 22:18:50 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_7.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:19:02 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 91.220 Acc@5 99.710\n",
      "\u001b[32m[2024-03-20 22:19:02 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 91.2%\n",
      "\u001b[32m[2024-03-20 22:19:02 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 91.22%\n",
      "\u001b[32m[2024-03-20 22:19:46 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [8/300][100/390]\teta 0:02:08 lr 0.000045\ttime 0.4292 (0.4401)\tloss 2.1586 (2.2049)\tgrad_norm 9.7563 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:20:29 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [8/300][200/390]\teta 0:01:23 lr 0.000047\ttime 0.4295 (0.4355)\tloss 2.4472 (2.1988)\tgrad_norm 6.4727 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:21:12 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [8/300][300/390]\teta 0:00:39 lr 0.000049\ttime 0.4301 (0.4341)\tloss 1.8727 (2.2065)\tgrad_norm 5.8327 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:21:51 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 8 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:21:51 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_8.pth saving......\n",
      "\u001b[32m[2024-03-20 22:21:52 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_8.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:22:04 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 92.260 Acc@5 99.780\n",
      "\u001b[32m[2024-03-20 22:22:04 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 92.3%\n",
      "\u001b[32m[2024-03-20 22:22:04 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 92.26%\n",
      "\u001b[32m[2024-03-20 22:22:48 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [9/300][100/390]\teta 0:02:08 lr 0.000052\ttime 0.4283 (0.4408)\tloss 2.6277 (2.2142)\tgrad_norm 8.5115 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:23:31 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [9/300][200/390]\teta 0:01:23 lr 0.000053\ttime 0.4294 (0.4352)\tloss 2.2496 (2.2335)\tgrad_norm 4.7968 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:24:14 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [9/300][300/390]\teta 0:00:39 lr 0.000055\ttime 0.4302 (0.4332)\tloss 2.2382 (2.2238)\tgrad_norm 10.8015 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:24:52 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 9 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:24:52 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_9.pth saving......\n",
      "\u001b[32m[2024-03-20 22:24:53 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_9.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:25:05 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 93.060 Acc@5 99.780\n",
      "\u001b[32m[2024-03-20 22:25:05 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 93.1%\n",
      "\u001b[32m[2024-03-20 22:25:05 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 93.06%\n",
      "\u001b[32m[2024-03-20 22:25:49 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [10/300][100/390]\teta 0:02:07 lr 0.000058\ttime 0.4291 (0.4394)\tloss 2.2531 (2.2060)\tgrad_norm 7.3315 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:26:32 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [10/300][200/390]\teta 0:01:22 lr 0.000060\ttime 0.4292 (0.4344)\tloss 2.1599 (2.2133)\tgrad_norm 5.4620 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:27:15 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [10/300][300/390]\teta 0:00:39 lr 0.000061\ttime 0.4293 (0.4328)\tloss 1.9897 (2.2101)\tgrad_norm 10.0879 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:27:54 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 10 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:27:54 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_10.pth saving......\n",
      "\u001b[32m[2024-03-20 22:27:54 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_10.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:28:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 93.850 Acc@5 99.890\n",
      "\u001b[32m[2024-03-20 22:28:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 93.8%\n",
      "\u001b[32m[2024-03-20 22:28:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 93.85%\n",
      "\u001b[32m[2024-03-20 22:28:50 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [11/300][100/390]\teta 0:02:07 lr 0.000064\ttime 0.4280 (0.4395)\tloss 1.8521 (2.1754)\tgrad_norm 5.9347 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:29:33 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [11/300][200/390]\teta 0:01:22 lr 0.000066\ttime 0.4289 (0.4340)\tloss 1.9912 (2.1674)\tgrad_norm 10.6513 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:30:16 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [11/300][300/390]\teta 0:00:39 lr 0.000067\ttime 0.4293 (0.4322)\tloss 2.1500 (2.1673)\tgrad_norm 7.4432 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:30:55 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 11 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:30:55 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_11.pth saving......\n",
      "\u001b[32m[2024-03-20 22:30:55 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_11.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:31:07 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.360 Acc@5 99.840\n",
      "\u001b[32m[2024-03-20 22:31:07 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 94.4%\n",
      "\u001b[32m[2024-03-20 22:31:07 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 94.36%\n",
      "\u001b[32m[2024-03-20 22:31:51 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [12/300][100/390]\teta 0:02:07 lr 0.000070\ttime 0.4305 (0.4398)\tloss 2.5277 (2.1588)\tgrad_norm 8.3962 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:32:34 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [12/300][200/390]\teta 0:01:23 lr 0.000072\ttime 0.4285 (0.4346)\tloss 1.7401 (2.1633)\tgrad_norm 7.0306 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:33:17 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [12/300][300/390]\teta 0:00:39 lr 0.000074\ttime 0.4292 (0.4330)\tloss 2.4508 (2.1785)\tgrad_norm 15.9161 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:33:56 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 12 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:33:56 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_12.pth saving......\n",
      "\u001b[32m[2024-03-20 22:33:56 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_12.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:34:09 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.300 Acc@5 99.870\n",
      "\u001b[32m[2024-03-20 22:34:09 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 94.3%\n",
      "\u001b[32m[2024-03-20 22:34:09 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 94.36%\n",
      "\u001b[32m[2024-03-20 22:34:52 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [13/300][100/390]\teta 0:02:07 lr 0.000077\ttime 0.4291 (0.4385)\tloss 2.1330 (2.1748)\tgrad_norm 9.7012 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:35:35 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [13/300][200/390]\teta 0:01:22 lr 0.000078\ttime 0.4320 (0.4341)\tloss 1.8417 (2.1463)\tgrad_norm 15.5539 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:36:18 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [13/300][300/390]\teta 0:00:39 lr 0.000080\ttime 0.4281 (0.4326)\tloss 2.3051 (2.1536)\tgrad_norm 25.4677 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:36:57 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 13 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:36:57 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_13.pth saving......\n",
      "\u001b[32m[2024-03-20 22:36:58 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_13.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:37:10 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.980 Acc@5 99.930\n",
      "\u001b[32m[2024-03-20 22:37:10 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.0%\n",
      "\u001b[32m[2024-03-20 22:37:10 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 94.98%\n",
      "\u001b[32m[2024-03-20 22:37:53 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [14/300][100/390]\teta 0:02:07 lr 0.000083\ttime 0.4293 (0.4386)\tloss 1.7203 (2.1526)\tgrad_norm 7.5309 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:38:37 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [14/300][200/390]\teta 0:01:22 lr 0.000084\ttime 0.4311 (0.4345)\tloss 2.3314 (2.1705)\tgrad_norm 9.5189 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:39:20 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [14/300][300/390]\teta 0:00:39 lr 0.000086\ttime 0.4294 (0.4331)\tloss 1.9500 (2.1658)\tgrad_norm 6.4315 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:39:58 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 14 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:39:58 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_14.pth saving......\n",
      "\u001b[32m[2024-03-20 22:39:59 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_14.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:40:11 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.960 Acc@5 99.890\n",
      "\u001b[32m[2024-03-20 22:40:11 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.0%\n",
      "\u001b[32m[2024-03-20 22:40:11 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 94.98%\n",
      "\u001b[32m[2024-03-20 22:40:55 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [15/300][100/390]\teta 0:02:08 lr 0.000089\ttime 0.4303 (0.4416)\tloss 1.6271 (2.1320)\tgrad_norm 9.5788 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:41:38 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [15/300][200/390]\teta 0:01:23 lr 0.000091\ttime 0.4309 (0.4365)\tloss 2.4015 (2.1411)\tgrad_norm 8.6651 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:42:21 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [15/300][300/390]\teta 0:00:39 lr 0.000092\ttime 0.4299 (0.4348)\tloss 2.5197 (2.1376)\tgrad_norm 8.6854 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:43:00 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 15 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:43:00 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_15.pth saving......\n",
      "\u001b[32m[2024-03-20 22:43:01 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_15.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:43:13 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.560 Acc@5 99.870\n",
      "\u001b[32m[2024-03-20 22:43:13 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 94.6%\n",
      "\u001b[32m[2024-03-20 22:43:13 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 94.98%\n",
      "\u001b[32m[2024-03-20 22:43:57 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [16/300][100/390]\teta 0:02:08 lr 0.000095\ttime 0.4308 (0.4418)\tloss 2.3481 (2.1816)\tgrad_norm 8.6632 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:44:40 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [16/300][200/390]\teta 0:01:23 lr 0.000097\ttime 0.4302 (0.4365)\tloss 2.2071 (2.1562)\tgrad_norm 7.8599 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:45:23 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [16/300][300/390]\teta 0:00:39 lr 0.000099\ttime 0.4305 (0.4347)\tloss 1.6817 (2.1427)\tgrad_norm 7.0748 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:46:02 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 16 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:46:02 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_16.pth saving......\n",
      "\u001b[32m[2024-03-20 22:46:03 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_16.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:46:15 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 95.210 Acc@5 99.910\n",
      "\u001b[32m[2024-03-20 22:46:15 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.2%\n",
      "\u001b[32m[2024-03-20 22:46:15 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.21%\n",
      "\u001b[32m[2024-03-20 22:46:59 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [17/300][100/390]\teta 0:02:08 lr 0.000102\ttime 0.4339 (0.4405)\tloss 2.1422 (2.2077)\tgrad_norm 6.5968 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:47:42 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [17/300][200/390]\teta 0:01:23 lr 0.000103\ttime 0.4346 (0.4360)\tloss 2.2405 (2.1798)\tgrad_norm 5.9567 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:48:25 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [17/300][300/390]\teta 0:00:39 lr 0.000105\ttime 0.4301 (0.4346)\tloss 2.4943 (2.1492)\tgrad_norm 8.1188 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:49:04 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 17 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:49:04 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_17.pth saving......\n",
      "\u001b[32m[2024-03-20 22:49:05 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_17.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:49:17 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 95.070 Acc@5 99.850\n",
      "\u001b[32m[2024-03-20 22:49:17 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.1%\n",
      "\u001b[32m[2024-03-20 22:49:17 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.21%\n",
      "\u001b[32m[2024-03-20 22:50:01 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [18/300][100/390]\teta 0:02:08 lr 0.000108\ttime 0.4328 (0.4422)\tloss 2.2000 (2.1270)\tgrad_norm 5.8470 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:50:44 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [18/300][200/390]\teta 0:01:23 lr 0.000109\ttime 0.4324 (0.4369)\tloss 2.1089 (2.1124)\tgrad_norm 6.4801 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:51:27 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [18/300][300/390]\teta 0:00:39 lr 0.000111\ttime 0.4312 (0.4353)\tloss 2.4783 (2.1025)\tgrad_norm 6.6817 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:52:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 18 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:52:06 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_18.pth saving......\n",
      "\u001b[32m[2024-03-20 22:52:07 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_18.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:52:19 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 94.900 Acc@5 99.870\n",
      "\u001b[32m[2024-03-20 22:52:19 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 94.9%\n",
      "\u001b[32m[2024-03-20 22:52:19 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.21%\n",
      "\u001b[32m[2024-03-20 22:53:03 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [19/300][100/390]\teta 0:02:08 lr 0.000114\ttime 0.4296 (0.4409)\tloss 1.7251 (2.0890)\tgrad_norm 9.5917 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:53:46 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [19/300][200/390]\teta 0:01:23 lr 0.000116\ttime 0.4288 (0.4360)\tloss 2.2370 (2.1146)\tgrad_norm 5.4013 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:54:29 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [19/300][300/390]\teta 0:00:39 lr 0.000117\ttime 0.4315 (0.4344)\tloss 1.6432 (2.1160)\tgrad_norm 11.8868 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:55:08 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 19 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 22:55:08 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_19.pth saving......\n",
      "\u001b[32m[2024-03-20 22:55:08 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_19.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:55:20 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 95.090 Acc@5 99.890\n",
      "\u001b[32m[2024-03-20 22:55:20 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.1%\n",
      "\u001b[32m[2024-03-20 22:55:20 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.21%\n",
      "\u001b[32m[2024-03-20 22:56:04 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [20/300][100/390]\teta 0:02:07 lr 0.000120\ttime 0.4291 (0.4393)\tloss 2.0506 (2.0976)\tgrad_norm 6.2912 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:56:47 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [20/300][200/390]\teta 0:01:22 lr 0.000122\ttime 0.4288 (0.4344)\tloss 2.3311 (2.0989)\tgrad_norm 6.4927 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:57:30 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [20/300][300/390]\teta 0:00:39 lr 0.000124\ttime 0.4282 (0.4328)\tloss 2.4474 (2.1080)\tgrad_norm 7.2887 (inf)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:58:09 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 20 training takes 0:02:48\n",
      "\u001b[32m[2024-03-20 22:58:09 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_20.pth saving......\n",
      "\u001b[32m[2024-03-20 22:58:09 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_20.pth saved !!!\n",
      "\u001b[32m[2024-03-20 22:58:22 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 95.330 Acc@5 99.900\n",
      "\u001b[32m[2024-03-20 22:58:22 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.3%\n",
      "\u001b[32m[2024-03-20 22:58:22 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.33%\n",
      "\u001b[32m[2024-03-20 22:59:06 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [21/300][100/390]\teta 0:02:08 lr 0.000124\ttime 0.4314 (0.4413)\tloss 1.7633 (2.1216)\tgrad_norm 10.0454 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 22:59:49 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [21/300][200/390]\teta 0:01:23 lr 0.000124\ttime 0.4300 (0.4359)\tloss 2.4211 (2.1095)\tgrad_norm 5.6217 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 23:00:32 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 248)\u001b[0m: INFO Train: [21/300][300/390]\teta 0:00:39 lr 0.000124\ttime 0.4293 (0.4341)\tloss 1.6603 (2.1032)\tgrad_norm 7.8027 (nan)\tmem 16792MB\n",
      "\u001b[32m[2024-03-20 23:01:11 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 256)\u001b[0m: INFO EPOCH 21 training takes 0:02:49\n",
      "\u001b[32m[2024-03-20 23:01:11 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 60)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_21.pth saving......\n",
      "\u001b[32m[2024-03-20 23:01:11 dat_plus_plus]\u001b[0m\u001b[33m(utils.py 62)\u001b[0m: INFO output/dat_plus_plus/tes/ckpt_epoch_21.pth saved !!!\n",
      "\u001b[32m[2024-03-20 23:01:23 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 301)\u001b[0m: INFO  * Acc@1 95.480 Acc@5 99.920\n",
      "\u001b[32m[2024-03-20 23:01:23 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 179)\u001b[0m: INFO Accuracy of the network on the 10000 test images: 95.5%\n",
      "\u001b[32m[2024-03-20 23:01:23 dat_plus_plus]\u001b[0m\u001b[33m(maincoba.py 181)\u001b[0m: INFO Max accuracy: 95.48%\n",
      "^C\n",
      "[2024-03-20 23:01:38,572] torch.distributed.elastic.agent.server.api: [WARNING] Received Signals.SIGINT death signal, shutting down workers\n",
      "[2024-03-20 23:01:38,575] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 4352 closing signal SIGINT\n",
      "Traceback (most recent call last):\n",
      "  File \"maincoba.py\", line 324, in <module>\n",
      "    main()\n",
      "  File \"maincoba.py\", line 172, in main\n",
      "    train_one_epoch(config, model, criterion, data_loader_train, optimizer, epoch, mixup_fn, lr_scheduler, logger)\n",
      "  File \"maincoba.py\", line 215, in train_one_epoch\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!bash traincoba.sh 1 configs/dat_tiny.yaml cifar_finetune dat_pp_tiny_in1k_224.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a208d-876e-4851-b5ec-8da9d6b995cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
